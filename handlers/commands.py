from aiogram import Router
from aiogram.enums import ParseMode
from aiogram.filters import Command, CommandStart
from aiogram.types import Message

router = Router()


@router.message(Command(commands=['start']))
async def start_handler(message: Message):
    welcome_text = """
üëã –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –±–æ—Ç–∞ - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞!

–Ø –º–æ–≥—É –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–∏—Ö —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–î–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –≤–∞—à —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã `/token`,
–∞ –∑–∞—Ç–µ–º –∑–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –≤–∞—à–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º.

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `/help` –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏.
"""
    await message.answer(
        welcome_text,
        parse_mode=ParseMode.MARKDOWN
    )


@router.message(Command(commands=['help']))
async def help_handler(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /help."""
    help_text = """
‚ÑπÔ∏è **–°–ø—Ä–∞–≤–∫–∞ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –±–æ—Ç–∞**

1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Ç–æ–∫–µ–Ω –∫–æ–º–∞–Ω–¥–æ–π:
`/token –≤–∞—à_—É–Ω–∏–∫–∞–ª—å–Ω—ã–π_—Ç–æ–∫–µ–Ω`

2. –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –≤–∞—à–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º

–ü—Ä–∏–º–µ—Ä:
`–ö–∞–∫–æ–π —É –≤–∞—à–µ–π –∫–æ–º–ø–∞–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã?`
"""
    await message.answer(
        help_text,
        parse_mode=ParseMode.MARKDOWN
    )


@router.message(Command(commands=['token']))
async def token_handler(message: Message, user_tokens, pipeline) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /token."""
    args = message.text.split(maxsplit=1)
    if len(args) < 2:
        await message.answer(
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ —Ç–æ–∫–µ–Ω –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã:\n"
            "`/token –≤–∞—à_—É–Ω–∏–∫–∞–ª—å–Ω—ã–π_—Ç–æ–∫–µ–Ω`",
            parse_mode=ParseMode.MARKDOWN
        )
        return

    token = args[1].strip()
    user_tokens[message.from_user.id] = token
    if token not in pipeline.document_store.list_user_tokens():
        await message.answer(
            "–í–∞—à —Ç–æ–∫–µ–Ω –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.\n"
            "`/token –≤–∞—à_—É–Ω–∏–∫–∞–ª—å–Ω—ã–π_—Ç–æ–∫–µ–Ω`",
            parse_mode=ParseMode.MARKDOWN
        )
        return

    documents = pipeline.document_store.file_store.list_documents(token)
    await message.answer(
        f"üîë –¢–æ–∫–µ–Ω —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: `{token}`\n\n"
        "–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –ø–æ –≤–∞—à–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º.\n"
        f"–°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤–∞—à–µ–≥–æ —Ç–æ–∫–µ–Ω–∞:\n{', '.join(documents)}",
        parse_mode=ParseMode.MARKDOWN
    )
