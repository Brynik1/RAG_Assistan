from aiogram import Router
from aiogram.enums import ParseMode
from aiogram.filters import Command, CommandStart
from aiogram.types import Message

router = Router()


@router.message(Command(commands=['start']))
async def start_handler(message: Message, user_tokens, pipeline):
    welcome_text = """
üëã –î–æ–±—Ä—ã–π –¥–µ–Ω—å! –Ø –≤–∞—à –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≠–º–∏–ª–∏!

–Ø –ø–æ–º–æ–≥—É –≤–∞–º –±—ã—Å—Ç—Ä–æ –Ω–∞—Ö–æ–¥–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –≤–∞—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö. –ü—Ä–æ—Å—Ç–æ –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –≤ —Å–≤–æ–±–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä:
   ‚Ä¢ –ö–∞–∫–æ–π –≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã –≤ –∫–æ–º–ø–∞–Ω–∏–∏?
"""
    token = "example"

    user_tokens[message.from_user.id] = token

    documents = pipeline.list_documents(token)
    await message.answer(
        welcome_text + f"\nüìÇ –í–∞—à–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã:\n\n" + "\n".join(f"‚Ä¢  {doc}" for doc in documents),
        parse_mode=ParseMode.MARKDOWN
    )


@router.message(Command(commands=['help']))
async def help_handler(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /help. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–ª–Ω—É—é —Å–ø—Ä–∞–≤–∫—É –ø–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—É –±–æ—Ç–∞."""
    help_text = """
üìö *–ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ñ—É–Ω–∫—Ü–∏—è–º*

üîπ *–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:*
`/start` - –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã —Å –±–æ—Ç–æ–º
`/help` - –≠—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ
`/token [–≤–∞—à_—Ç–æ–∫–µ–Ω]` - –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤–∞—à –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω –¥–æ—Å—Ç—É–ø–∞
`/documents` - –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –≤–∞—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

üîπ *–ö–∞–∫ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –±–æ—Ç–æ–º:*
1. –°–Ω–∞—á–∞–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤–∞—à —Ç–æ–∫–µ–Ω:
`/token 12345abcde`

2. –ó–∞—Ç–µ–º –º–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –ø–æ –≤–∞—à–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º:
   ‚Ä¢ –ö–∞–∫–æ–π –≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã –≤ –∫–æ–º–ø–∞–Ω–∏–∏?
   ‚Ä¢ –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∂–∞—Ä–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏?
   ‚Ä¢ –ü–æ–ª–æ–∂–µ–Ω–∏–µ –æ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–π —Ç–∞–π–Ω–µ?

üîπ *–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç—ã:*
   ‚Ä¢ –ë–æ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –≤–∞—à–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã
   ‚Ä¢ –û—Ç–≤–µ—Ç—ã —Ñ–æ—Ä–º–∏—Ä—É—é—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
"""
    await message.answer(
        help_text,
        parse_mode=ParseMode.MARKDOWN
    )


@router.message(Command(commands=['token']))
async def token_handler(message: Message, user_tokens, pipeline) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /token."""
    args = message.text.split(maxsplit=1)
    if len(args) < 2:
        await message.answer(
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ —Ç–æ–∫–µ–Ω –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã:\n"
            "`/token –≤–∞—à_—É–Ω–∏–∫–∞–ª—å–Ω—ã–π_—Ç–æ–∫–µ–Ω`",
            parse_mode=ParseMode.MARKDOWN
        )
        return

    token = args[1].strip()
    if token not in pipeline.document_store.list_user_tokens():
        await message.answer(
            "–í–∞—à —Ç–æ–∫–µ–Ω –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.\n"
            "`/token –≤–∞—à_—É–Ω–∏–∫–∞–ª—å–Ω—ã–π_—Ç–æ–∫–µ–Ω`",
            parse_mode=ParseMode.MARKDOWN
        )
        user_tokens.pop(message.from_user.id, None)
        return

    user_tokens[message.from_user.id] = token

    documents = pipeline.list_documents(token)
    await message.answer(
        f"üîë –¢–æ–∫–µ–Ω —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: `{token}`\n\n"
        "–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –ø–æ –≤–∞—à–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º.\n\n"
        f"üìÇ –í–∞—à–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã:\n\n" + "\n".join(f"‚Ä¢  {doc}" for doc in documents),
        parse_mode=ParseMode.MARKDOWN
    )


@router.message(Command(commands=['documents']))
async def documents_handler(message: Message, user_tokens, pipeline) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    if message.from_user.id not in user_tokens:
        await message.answer(
            "‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Ç–æ–∫–µ–Ω —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã `/token`\n\n"
            "–ü—Ä–∏–º–µ—Ä: `/token –≤–∞—à_—É–Ω–∏–∫–∞–ª—å–Ω—ã–π_—Ç–æ–∫–µ–Ω`",
            parse_mode=ParseMode.MARKDOWN
        )
        return

    token = user_tokens[message.from_user.id]
    documents = pipeline.list_documents(token)

    if not documents:
        await message.answer("–î–ª—è –≤–∞—à–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return

    await message.answer(
        f"üìÇ –í–∞—à–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã:\n\n" + "\n".join(f"‚Ä¢  {doc}" for doc in documents),
        parse_mode=ParseMode.MARKDOWN
    )